{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70d9800-20ea-4e37-9932-8898b4dd02e7",
   "metadata": {},
   "source": [
    "Question 1. what is ensemble learning in machine learning? explain the key idea behind it.\n",
    "\n",
    "Answer - Ensemble learning in machine learning refers to a technique where multiple models, often called base learners, are trained to solve the same problem, and their predictions are combined to produce a better overall result. The key idea behind ensemble learning is that while individual models may have limitations and errors, combining several models can compensate for each other's weaknesses, leading to improved accuracy, robustness, and generalization. It works on the principle that a group of models, each bringing different viewpoints or learned patterns, can collectively make more reliable and accurate predictions than any single model alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef515849-9ad1-4a8a-b958-31b4cc0de4af",
   "metadata": {},
   "source": [
    "Question 2. what is the difference between bagging and boosting ?\n",
    "\n",
    "Answer - Bagging and Boosting are both ensemble learning techniques used to improve the performance of machine learning models, but they work in very different ways.\n",
    "\n",
    "Bagging, short for Bootstrap Aggregating, works by creating multiple subsets of the original dataset using random sampling with replacement (bootstrap sampling). Each subset is used to train an independent base model, often a decision tree. These models learn in parallel, and their predictions are combined through averaging or voting to make the final decision. Bagging primarily aims to reduce the variance of the model and helps to avoid overfitting. A classic example of bagging is the Random Forest algorithm.\n",
    "\n",
    "On the other hand, Boosting builds models sequentially. Each new model tries to correct the errors made by the previous models by paying more attention to the data points that were misclassified or predicted with high error. This is done by assigning weights to the training instances; instances that were misclassified get higher weights so the next model focuses more on them. Boosting attempts to reduce bias and can also reduce variance, but it’s more prone to overfitting if not carefully tuned. Examples of boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d9aa1-59eb-451c-9956-1f4e4e9ec13f",
   "metadata": {},
   "source": [
    "Question 3. what is bootstrap sampling and what role does it play in bagging methods like random forest.\n",
    "Answer - Bootstrap sampling is a technique where datasets are created by randomly selecting samples from the original dataset with replacement. This means that some data points may be repeated in a bootstrap sample, while others might be omitted. Each bootstrap sample is typically the same size as the original dataset but varies in composition due to this random selection process.\n",
    "Role in Bagging Methods like Random Forest\n",
    "In bagging (Bootstrap Aggregating), bootstrap sampling is used to generate multiple different training datasets for each base learner (e.g., decision trees).\n",
    "Each base model is trained independently on its own bootstrap sample, introducing variety among the models.\n",
    "This diversity among base learners reduces variance and overfitting, as the ensemble aggregates predictions from models trained on different data distributions.\n",
    "For Random Forests, bootstrap sampling is combined with random feature selection, further enhancing diversity and robustness.\n",
    "Additionally, samples not included in a bootstrap sample, called out-of-bag (OOB) samples, serve as a convenient, unbiased validation set to estimate model performance without needing a separate test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2db456-1813-4a5f-81bb-065ddcff7d6f",
   "metadata": {},
   "source": [
    "Question 4.what are out-of-bag samples and how is OOB score used to evaluate ensemble model.\n",
    "\n",
    "Answer - Out-of-Bag (OOB) Samples are the subset of training data instances not included in the bootstrap sample used to train a single tree in an ensemble method like Random Forest or Bagging. Since bootstrap sampling is done with replacement, approximately one-third of the training data is left out (not selected) for each tree — these are the OOB samples for that tree.\n",
    "\n",
    "How is the OOB Score Used to Evaluate Ensemble Models?\n",
    "In Random Forests and bagging ensembles, each tree is trained on a bootstrap sample (about 2/3 of data). The remaining out-of-bag samples serve as a built-in validation set for that specific tree.\n",
    "To compute the OOB score:\n",
    "For each training instance, collect predictions only from trees that did not use it for training (i.e., where it was OOB).\n",
    "Aggregate these predictions (e.g., majority vote for classification or average for regression).\n",
    "compare the aggregated prediction against the true label for every instance.\n",
    "Calculate the overall error or accuracy across all instances based on these OOB predictions.\n",
    "This OOB score gives an unbiased estimate of the model's generalization performance without needing a separate validation or test set, effectively mimicking cross-validation internally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8356a3-7432-495c-95e7-710a25bf3dae",
   "metadata": {},
   "source": [
    "Question 5. compare feature importance analysis in a single deciesion tree vs a random forest.\n",
    "\n",
    "Answer. Single Decision Tree Feature Importance\n",
    "A Decision Tree calculates feature importance based on how much each feature decreases impurity (e.g., Gini impurity or entropy) when used to split the data in the tree nodes.\n",
    "The importance scores are straightforward to interpret because the model is a single tree, making it easy to trace why a specific feature is considered important.\n",
    "However, due to the model's high variance, the feature importance can be unstable and sensitive to small changes in the data.\n",
    "Decision Trees are prone to overfitting, so feature importance from a single tree might overemphasize features relevant only to that specific training set, leading to unreliable interpretation especially in noisy or complex datasets.\n",
    "\n",
    "Random Forest Feature Importance\n",
    "A Random Forest aggregates feature importance scores from multiple decision trees, each trained on a random subset of data and a random subset of features.\n",
    "This ensemble approach reduces variance and provides more stable and reliable estimates of feature importance because the scores reflect average importance across many trees.\n",
    "Random Forests introduce randomness through bootstrap sampling and feature selection at each split, which helps to diminish bias towards correlated features and compensates for overfitting evident in a single tree.\n",
    "Although Random Forests are less interpretable as a whole compared to a single tree, they provide a robust and generalized view of which features are truly influential across multiple models.\n",
    "Feature importance in Random Forests thus tends to be more trustworthy for complex datasets and better reflects the overall predictive power of features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665af92-3ca1-40e8-a5ae-f697de1eb4de",
   "metadata": {},
   "source": [
    "Question 6. write a python program to :\n",
    " - load the breast cancer dataset using\n",
    " - sklearn.dataset.load_breast_cancer()\n",
    " - train a random forest classifier\n",
    " - print the top 5 most important features based on feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6030b14d-9d2f-4e14-a5b1-513aa82c0cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most important features:\n",
      "worst area: 0.1394\n",
      "worst concave points: 0.1322\n",
      "mean concave points: 0.1070\n",
      "worst radius: 0.0828\n",
      "worst perimeter: 0.0808\n"
     ]
    }
   ],
   "source": [
    "#Answer 6\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "top5_indices = np.argsort(importances)[-5:][::-1]\n",
    "print(\"Top 5 most important features:\")\n",
    "for i in top5_indices:\n",
    "    print(f\"{feature_names[i]}: {importances[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a40088-7f17-4674-ba3e-fe890a9b643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0000\n",
      "Bagging Classifier Accuracy: 1.0000\n",
      "Single Decision Tree performs equal to or better than Bagging Classifier.\n"
     ]
    }
   ],
   "source": [
    "# Question 7. write a python program to :\n",
    "#- train a bagging classifier using deciesion trees on the iris dataset\n",
    "#- evaluate its accuracy and compare with a sngle deciesion tree\n",
    "#Answer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "acc_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f\"Decision Tree Accuracy: {acc_tree:.4f}\")\n",
    "\n",
    "bagging = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "acc_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "print(f\"Bagging Classifier Accuracy: {acc_bagging:.4f}\")\n",
    "\n",
    "if acc_bagging > acc_tree:\n",
    "    print(\"Bagging Classifier performs better than a single Decision Tree.\")\n",
    "else:\n",
    "    print(\"Single Decision Tree performs equal to or better than Bagging Classifier.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b064a1d-4c36-44f5-83b5-397c8a2bfb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Final Accuracy on Test Data: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Question 8. Write a Python program to: \n",
    "#● Train a Random Forest Classifier \n",
    "#● Tune hyperparameters max_depth and n_estimators using GridSearchCV \n",
    "#● Print the best parameters and final accuracy\n",
    "#Answer\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10, 20]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,              \n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1          \n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Final Accuracy on Test Data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04b20e8-c2f1-40bf-afdc-4a8de3a582a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE: 0.2824\n",
      "Random Forest Regressor MSE: 0.2554\n"
     ]
    }
   ],
   "source": [
    "#Question 9: Write a Python program to: \n",
    "#● Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset \n",
    "#● Compare their Mean Squared Errors (MSE)\n",
    "#Answer - \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "bagging = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Bagging Regressor MSE: {mse_bagging:.4f}\")\n",
    "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df638231-5fa5-418c-8c76-8f795c8c62c1",
   "metadata": {},
   "source": [
    "Question 10: You are working as a data scientist at a financial institution to predict loan \n",
    "default. You have access to customer demographic and transaction history data. \n",
    "You decide to use ensemble techniques to increase model performance. \n",
    "Explain your step-by-step approach to: \n",
    "● Choose between Bagging or Boosting \n",
    "● Handle overfitting \n",
    "● Select base models \n",
    "● Evaluate performance using cross-validation \n",
    "● Justify how ensemble learning improves decision-making in this real-world \n",
    "context.\n",
    "Answer - Choosing Between Bagging or Boosting\n",
    "Bagging (e.g., Random Forest) reduces variance by training multiple models independently on bootstrap samples and aggregating their predictions.\n",
    "\n",
    "Boosting (e.g., XGBoost) sequentially trains models, each correcting errors from the previous, and typically reduces bias.\n",
    "\n",
    "For loan default prediction, Boosting algorithms (such as XGBoost, CatBoost, and LightGBM) have demonstrated higher performance and accuracy over Bagging, especially with complex or imbalanced financial data. However, Bagging can be preferred if the primary challenge is high variance or if simple, interpretable models are required.\n",
    "\n",
    "Handling Overfitting\n",
    "Regularization techniques are essential: use tree pruning (limit tree depth), shrinkage/learning rate (reduce impact of each boosted tree), and early stopping (halt training when validation error doesn't improve).\n",
    "\n",
    "Data techniques: employ bootstrap sampling in Bagging to increase diversity, data augmentation for more robust modeling, and ensure sufficient feature engineering.\n",
    "\n",
    "Hyperparameter tuning: optimize depth, number of trees, learning rates, and use cross-validation to avoid fitting too closely to training patterns.\n",
    "\n",
    "Monitor validation performance: track performance on a separate validation set and stop training or adjust parameters as soon as signs of overfitting appear.\n",
    "\n",
    "Selecting Base Models\n",
    "For Bagging, base learners are often Decision Trees or Logistic Regression due to their stability and interpretability on financial data.\n",
    "\n",
    "For Boosting, base models such as trees are preferred, but simpler learners (e.g., regression stumps) can reduce complexity.\n",
    "\n",
    "Consider model performance, interpretability, and the ability to handle imbalance to select suitable base models for ensemble construction.\n",
    "\n",
    "Evaluating Performance Using Cross-Validation\n",
    "Use K-Fold Cross-Validation, which divides data into 'k' subsets, trains on 'k-1' and tests on the remaining one, repeating for each fold.\n",
    "\n",
    "Key metrics for loan default: Accuracy, Precision, Recall, F1 Score, and ROC-AUC to address class imbalance and business importance of false positives/negatives.\n",
    "\n",
    "Cross-validation ensures the ensemble generalizes well to unseen data, and mitigates the impact of random splits or data shifts in financial scenarios.\n",
    "\n",
    "How Ensemble Learning Improves Decision-Making\n",
    "Accuracy and robustness: Aggregating multiple models reduces variance, stabilizes predictions, and improves generalizability, crucial in noisy and complex financial datasets.\n",
    "\n",
    "Resilience to noise and outliers: Ensembles dilute influence of anomalous data, offering more consistent risk assessment.\n",
    "\n",
    "Better risk management: Ensembles provide more reliable probability estimates for defaults, supporting superior risk-based lending and regulatory compliance.\n",
    "\n",
    "Adaptivity: Ensembles can quickly adapt to changes in patterns of default and evolving customer behaviors, providing institutions with a competitive edge\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
